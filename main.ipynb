{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_search import SemanticSearch \n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import openai\n",
    "import praw\n",
    "import os\n",
    "import re\n",
    "\n",
    "pd.set_option('max_colwidth', 100)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher = SemanticSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDDIT_CLIENT_ID = os.environ.get('REDDIT_CLIENT_ID')\n",
    "REDDIT_CLIENT_SECRET = os.environ.get('REDDIT_CLIENT_SECRET')\n",
    "REDDIT_USER_AGENT = os.environ.get('REDDIT_USER_AGENT')\n",
    "\n",
    "reddit = praw.Reddit(client_id=REDDIT_CLIENT_ID, client_secret=REDDIT_CLIENT_SECRET, user_agent=REDDIT_USER_AGENT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topics(query, model=\"gpt-3.5-turbo\"):\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"Take this query '{query}' and return a list of short topics to input in Search so it returns good results. Each topic must stand on its own with respect to the relation of the question.\"},\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    topics = re.sub(r'^\\d+\\.\\s*', '', response_message, flags=re.MULTILINE).split(\"\\n\")\n",
    "\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Where are some nice places where I can work remotely in Malta?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = generate_topics(query)\n",
    "topics = [topic.strip() for topic in topics]\n",
    "print(topics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant Subreddits Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = []\n",
    "\n",
    "for topic in topics:\n",
    "    for post in reddit.subreddit(\"all\").search(\n",
    "    topic, limit=200):\n",
    "        posts.append([post.title, post.subreddit, post.selftext])\n",
    "\n",
    "posts = pd.DataFrame(posts,columns=['title', 'subreddit', 'text'])\n",
    "\n",
    "# Segments is title, text and subreddit at the end\n",
    "segments = (posts['title'] + ' ' + posts['subreddit'].astype(str)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.fit(segments, n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add distance check here\n",
    "subreddits = set([result.split()[-1] for result in searcher(query)])\n",
    "\n",
    "# Convert to string and \"+\" in between\n",
    "subreddits = \"+\".join(subreddits)\n",
    "\n",
    "print(f\"Relevant subreddits: {subreddits}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant Posts Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = []\n",
    "segment_length = 100\n",
    "\n",
    "\n",
    "for topic in topics:\n",
    "    for post in reddit.subreddit(subreddits).search(\n",
    "        topic, limit=50):\n",
    "            \n",
    "            comments = \"\"\n",
    "\n",
    "            post.comments.replace_more(limit=3)\n",
    "            for comment in post.comments.list():\n",
    "                if comment.body != \"[deleted]\":\n",
    "                    comments += comment.body + \"\\n\"\n",
    "\n",
    "            words = comments.split()\n",
    "            segments.extend([post.title + \" \" + post.id + \"\\n\" + ' '.join(words[i:i+segment_length]) for i in range(0, len(words), segment_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.fit(segments, n_neighbors=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering the Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens(text, model):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_query(query, model, token_budget):\n",
    "\n",
    "    relevant_segments = searcher(query)\n",
    "\n",
    "    introduction = 'Use the below segments from multiple Reddit posts to answer the subsequent question. If the answer cannot be found in the articles, write \"I could not find an answer.\" Cite each sentence using the [postid] notation found at the start of each segment. Every sentence MUST have a citation!\\n\\n'\n",
    "\n",
    "    message = introduction\n",
    "\n",
    "    query = f\"\\n\\nQuestion: {query}\"\n",
    "\n",
    "    evidence = []\n",
    "\n",
    "    for i, result in enumerate(relevant_segments):\n",
    "        if (\n",
    "            num_tokens(message + result + query, model=model)\n",
    "            > token_budget\n",
    "        ):\n",
    "            break\n",
    "        else:\n",
    "            result = result + \"\\n\\n\"\n",
    "            message += result\n",
    "            evidence.append(result.split(\"\\n\")[0])\n",
    "\n",
    "    evidence = list(set(evidence))\n",
    "\n",
    "    return message + query, evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query, model, token_budget, temperature):\n",
    "    \n",
    "    message, evidence = form_query(query, model, token_budget)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "\n",
    "    print(message)\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    return response_message, evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer, evidence = generate_answer(query, \"gpt-3.5-turbo\", 1000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
